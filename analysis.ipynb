{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LDj7zFHG564s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "from tqdm.notebook import tqdm\n",
        "from random import randint\n",
        "import inflect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPwbwt0u6DAQ",
        "outputId": "dfc608da-215e-436d-b54d-6f42aa41e625"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 10k samples, only ran for zero shot and one shot\n",
        "master10=pd.read_csv(\"/content/drive/MyDrive/Crosswords/full_10k_sample_fs_1.csv\", encoding='cp1252',index_col=0) #change_path\n",
        "### 5k samples, ran for zero shot, one shot and three shot\n",
        "master5=pd.read_csv(\"/content/drive/MyDrive/Crosswords/full_5k_sample_fs.csv\", encoding='cp1252',index_col=0) #change path"
      ],
      "metadata": {
        "id": "E2K-_MbX6Ffu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master10.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtUNMRVR6ffj",
        "outputId": "ab0d1887-8f99-40ab-fe16-c7948870d9dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['index', 'date', 'answer', 'clue', 'answer_length', 'baseline_prompt',\n",
              "       'baseline_prompt_output', 'random', 'random_ordinal', 'random_letter',\n",
              "       'constrained_prompt', 'constrained_prompt_output', 'fs_random',\n",
              "       'fs_random_ordinal', 'fs_random_letter', 'few_shot_constrained_1',\n",
              "       'few_shot_constrained_1_output', 'few_shot_baseline_1',\n",
              "       'few_shot_baseline_1_output'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##EVAL FUNCTIONS\n",
        "def acc_eval(df,batch_output_column_name):\n",
        "    acc=np.sum(df['answer']==df[batch_output_column_name])/len(df)\n",
        "    return acc\n",
        "\n",
        "def percent_punct(df,batch_output_column_name):\n",
        "    df['no_punct'] = df[batch_output_column_name].apply(lambda x:str(x).isalpha())\n",
        "    punt_percent=1-np.sum(df['no_punct'])/len(df)\n",
        "    return punt_percent\n",
        "\n",
        "def acc_norm_eval(df,batch_output_column_name):\n",
        "    #df['cleaned_output']=df[batch_output_column_name].str.replace(r'[\\W\\s]+', '')\n",
        "    df['cleaned_output']=df[batch_output_column_name].apply(lambda x: strip_punct(str(x)))\n",
        "    acc_norm=np.sum(df['answer']==df['cleaned_output'])/len(df)\n",
        "    return acc_norm\n",
        "\n",
        "def letter_match(df,batch_output_column_name):\n",
        "    df['output_length'] = df[batch_output_column_name].apply(lambda x:len(str(x)))\n",
        "    match=np.sum(df[\"output_length\"]==df['answer_length'])/len(df)\n",
        "    return match\n",
        "\n",
        "def norm_letter_match(df,batch_output_column_name):\n",
        "    df['cleaned_output']=df[batch_output_column_name].apply(lambda x: strip_punct(str(x)))\n",
        "    df['output_length'] = df['cleaned_output'].apply(lambda x:len(str(x)))\n",
        "    match=np.sum(df[\"output_length\"]==df['answer_length'])/len(df)\n",
        "    return match\n",
        "\n",
        "\n",
        "def strip_punct(s):\n",
        "    s = ''.join(filter(str.isalnum, s)).lower()\n",
        "    return s\n",
        "  \n",
        "def constraint_match(df,batch_output_column_name, is_fs=None):\n",
        "    ### matches in letter and matches with the letter at the right spot\n",
        "    ## match letter lengths\n",
        "    if is_fs is None:\n",
        "      is_fs = 'few_shot' in batch_output_column_name\n",
        "    if is_fs:\n",
        "      random_col = 'fs_random'\n",
        "    else:\n",
        "      random_col = 'random'\n",
        "    df['output_length'] = df[batch_output_column_name].apply(lambda x:len(str(x)))\n",
        "    match=np.sum(df[\"output_length\"]==df['answer_length'])/len(df)  \n",
        "    df['constrained_output_letter'] = [str(row[batch_output_column_name])[row[random_col]-1] if row[random_col] <= len(str(row[batch_output_column_name])) else None for _, row in df.iterrows()]\n",
        "    df['is_match'] = df['{}_letter'.format(random_col)].eq(df['constrained_output_letter'])\n",
        "    df['is_length_match'] = df[\"output_length\"].eq(df['answer_length'])\n",
        "    match = ((df['is_match']==True) & (df[\"is_length_match\"]==True)).sum()/len(df)\n",
        "    return match\n",
        "\n",
        "def constraint_norm_match(df,batch_output_column_name):\n",
        "    ### matches in letter and matches with the letter at the right spot, match letter length \n",
        "    ## TO-DO\n",
        "    df['cleaned_output'] = df[batch_output_column_name].apply(lambda x: strip_punct(str(x)))\n",
        "    is_fs = 'few_shot' in batch_output_column_name\n",
        "    return constraint_match(df, 'cleaned_output', is_fs)"
      ],
      "metadata": {
        "id": "R6I5Qw5m6HZX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EM ACCURACY\")\n",
        "### Running accurcy for 10k samples\n",
        "prompt_type_10=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(acc_eval(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output','few_shot_baseline_3_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(acc_eval(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qztz67uv6byP",
        "outputId": "fbc3dfa3-27ef-444b-a9df-dcc885d33393"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EM ACCURACY\n",
            "baseline_prompt_output\n",
            "0.2135\n",
            "constrained_prompt_output\n",
            "0.2706\n",
            "few_shot_baseline_1_output\n",
            "0.3304\n",
            "few_shot_constrained_1_output\n",
            "0.3594\n",
            "-------\n",
            "baseline_prompt_output\n",
            "0.2144\n",
            "constrained_prompt_output\n",
            "0.2774\n",
            "few_shot_baseline_1_output\n",
            "0.3374\n",
            "few_shot_constrained_1_output\n",
            "0.362\n",
            "few_shot_baseline_3_output\n",
            "0.3582\n",
            "few_shot_constrained_3_output\n",
            "0.3756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EM NORM\") #Accuracy after striping punctuation and spaces\n",
        "prompt_type_10=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(acc_norm_eval(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output','few_shot_baseline_3_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(acc_norm_eval(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCM22Ix7Jb5",
        "outputId": "11a6d54d-ed3b-4e42-fb3f-cddd88e7da20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EM NORM\n",
            "baseline_prompt_output\n",
            "0.2867\n",
            "constrained_prompt_output\n",
            "0.3325\n",
            "few_shot_baseline_1_output\n",
            "0.3499\n",
            "few_shot_constrained_1_output\n",
            "0.3768\n",
            "-------\n",
            "baseline_prompt_output\n",
            "0.2904\n",
            "constrained_prompt_output\n",
            "0.3386\n",
            "few_shot_baseline_1_output\n",
            "0.3554\n",
            "few_shot_constrained_1_output\n",
            "0.3762\n",
            "few_shot_baseline_3_output\n",
            "0.3756\n",
            "few_shot_constrained_3_output\n",
            "0.3892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PERCENT PUNCTUATION\") ## 1 shot was effective in showing gpt that answers do not contain punctuation\n",
        "prompt_type_10=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(percent_punct(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output','few_shot_baseline_3_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(percent_punct(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Ga_2_W9E0f",
        "outputId": "c0119ab2-4985-4ee1-a0a9-c1769ee99fe4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PERCENT PUNCTUATION\n",
            "baseline_prompt_output\n",
            "0.39349999999999996\n",
            "constrained_prompt_output\n",
            "0.3116\n",
            "few_shot_baseline_1_output\n",
            "0.06879999999999997\n",
            "few_shot_constrained_1_output\n",
            "0.06669999999999998\n",
            "-------\n",
            "baseline_prompt_output\n",
            "0.39239999999999997\n",
            "constrained_prompt_output\n",
            "0.3014\n",
            "few_shot_baseline_1_output\n",
            "0.06340000000000001\n",
            "few_shot_constrained_1_output\n",
            "0.059599999999999986\n",
            "few_shot_baseline_3_output\n",
            "0.07120000000000004\n",
            "few_shot_constrained_3_output\n",
            "0.06920000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LETTER MATCH\") ## more examples allowed model to learn importance of letter size clue\n",
        "prompt_type_10=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(letter_match(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output','few_shot_baseline_3_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(letter_match(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-C6e31x9c89",
        "outputId": "0020e13e-d6b4-4199-9ee6-d1d487ea32dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LETTER MATCH\n",
            "baseline_prompt_output\n",
            "0.4958\n",
            "constrained_prompt_output\n",
            "0.5317\n",
            "few_shot_baseline_1_output\n",
            "0.6742\n",
            "few_shot_constrained_1_output\n",
            "0.6811\n",
            "-------\n",
            "baseline_prompt_output\n",
            "0.4956\n",
            "constrained_prompt_output\n",
            "0.5408\n",
            "few_shot_baseline_1_output\n",
            "0.681\n",
            "few_shot_constrained_1_output\n",
            "0.6926\n",
            "few_shot_baseline_3_output\n",
            "0.66\n",
            "few_shot_constrained_3_output\n",
            "0.6792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Norm LETTER MATCH\") ## more examples allowed model to learn importance of letter size clue\n",
        "prompt_type_10=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(norm_letter_match(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['baseline_prompt_output','constrained_prompt_output', 'few_shot_baseline_1_output','few_shot_constrained_1_output','few_shot_baseline_3_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(norm_letter_match(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfM_6nEi1wRp",
        "outputId": "7a0e9755-e7d3-4ee6-e9e3-c9753c661cc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm LETTER MATCH\n",
            "baseline_prompt_output\n",
            "0.6321\n",
            "constrained_prompt_output\n",
            "0.6366\n",
            "few_shot_baseline_1_output\n",
            "0.6956\n",
            "few_shot_constrained_1_output\n",
            "0.698\n",
            "-------\n",
            "baseline_prompt_output\n",
            "0.6354\n",
            "constrained_prompt_output\n",
            "0.6456\n",
            "few_shot_baseline_1_output\n",
            "0.6984\n",
            "few_shot_constrained_1_output\n",
            "0.707\n",
            "few_shot_baseline_3_output\n",
            "0.6778\n",
            "few_shot_constrained_3_output\n",
            "0.6942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate constraint match for constrained prompts\n",
        "print(\"CONSTRAINT NORM MATCH\") \n",
        "prompt_type_10=['constrained_prompt_output', 'few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(constraint_norm_match(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['constrained_prompt_output', 'few_shot_constrained_1_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(constraint_norm_match(master5,prompt))"
      ],
      "metadata": {
        "id": "8tEd04NT-dNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9184df-2e1e-4f28-bae5-2dc2282d7863"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONSTRAINT NORM MATCH\n",
            "constrained_prompt_output\n",
            "0.4408\n",
            "few_shot_constrained_1_output\n",
            "0.5001\n",
            "-------\n",
            "constrained_prompt_output\n",
            "0.4488\n",
            "few_shot_constrained_1_output\n",
            "0.4426\n",
            "few_shot_constrained_3_output\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate constraint match for constrained prompts\n",
        "print(\"CONSTRAINT MATCH\") \n",
        "prompt_type_10=['constrained_prompt_output', 'few_shot_constrained_1_output']\n",
        "for prompt in prompt_type_10:\n",
        "  print(prompt)\n",
        "  print(constraint_match(master10,prompt))\n",
        "print(\"-------\")\n",
        "### running accuracy for 5k samples: \n",
        "prompt_type_5=['constrained_prompt_output', 'few_shot_constrained_1_output','few_shot_constrained_3_output']\n",
        "for prompt in prompt_type_5:\n",
        "  print(prompt)\n",
        "  print(constraint_match(master5,prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTbTzjLmv1eo",
        "outputId": "c51ad34d-bcea-4749-dedb-cc24982c5bbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONSTRAINT MATCH\n",
            "constrained_prompt_output\n",
            "0.3627\n",
            "few_shot_constrained_1_output\n",
            "0.4825\n",
            "-------\n",
            "constrained_prompt_output\n",
            "0.369\n",
            "few_shot_constrained_1_output\n",
            "0.4276\n",
            "few_shot_constrained_3_output\n",
            "0.4854\n"
          ]
        }
      ]
    }
  ]
}